{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature5998</th>\n",
       "      <th>feature5999</th>\n",
       "      <th>feature6000</th>\n",
       "      <th>feature6001</th>\n",
       "      <th>feature6002</th>\n",
       "      <th>feature6003</th>\n",
       "      <th>feature6004</th>\n",
       "      <th>feature6005</th>\n",
       "      <th>feature6006</th>\n",
       "      <th>emotion_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>148</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>146</td>\n",
       "      <td>196</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>151</td>\n",
       "      <td>203</td>\n",
       "      <td>49</td>\n",
       "      <td>106</td>\n",
       "      <td>158</td>\n",
       "      <td>57</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>135</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>184</td>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>141</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>155</td>\n",
       "      <td>208</td>\n",
       "      <td>53</td>\n",
       "      <td>105</td>\n",
       "      <td>158</td>\n",
       "      <td>52</td>\n",
       "      <td>105</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>164</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>158</td>\n",
       "      <td>212</td>\n",
       "      <td>54</td>\n",
       "      <td>109</td>\n",
       "      <td>163</td>\n",
       "      <td>55</td>\n",
       "      <td>109</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>158</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>161</td>\n",
       "      <td>213</td>\n",
       "      <td>54</td>\n",
       "      <td>109</td>\n",
       "      <td>161</td>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>156</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>153</td>\n",
       "      <td>208</td>\n",
       "      <td>53</td>\n",
       "      <td>109</td>\n",
       "      <td>164</td>\n",
       "      <td>56</td>\n",
       "      <td>111</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>161</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>169</td>\n",
       "      <td>227</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>174</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>136</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>142</td>\n",
       "      <td>190</td>\n",
       "      <td>48</td>\n",
       "      <td>97</td>\n",
       "      <td>145</td>\n",
       "      <td>49</td>\n",
       "      <td>97</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>159</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>160</td>\n",
       "      <td>215</td>\n",
       "      <td>55</td>\n",
       "      <td>111</td>\n",
       "      <td>166</td>\n",
       "      <td>56</td>\n",
       "      <td>111</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0           39        19         2        21        36        16         5   \n",
       "1           30        17         5        12        30        15         2   \n",
       "2           30        14         1        18        35        19         2   \n",
       "3           34        20         3        15        32        17         0   \n",
       "4           44        24         2        20        40        19         2   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995        31        16         2        19        28        13         3   \n",
       "1996        34        21         1        22        40        19         1   \n",
       "1997        33        18         2        22        39        21         3   \n",
       "1998        33        18         1        19        33        15         3   \n",
       "1999        33        20         1        22        39        21         3   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature5998  feature5999  \\\n",
       "0           24       148        114  ...           96          146   \n",
       "1           11       143        114  ...           94          151   \n",
       "2           15       135        106  ...           97          144   \n",
       "3           17       141        109  ...          103          155   \n",
       "4           23       164        122  ...          103          158   \n",
       "...        ...       ...        ...  ...          ...          ...   \n",
       "1995        18       158        133  ...          106          161   \n",
       "1996        18       156        119  ...           97          153   \n",
       "1997        16       161        122  ...          111          169   \n",
       "1998        22       136        106  ...           93          142   \n",
       "1999        16       159        120  ...          104          160   \n",
       "\n",
       "      feature6000  feature6001  feature6002  feature6003  feature6004  \\\n",
       "0             196           50          100          150           50   \n",
       "1             203           49          106          158           57   \n",
       "2             184           46           93          133           47   \n",
       "3             208           53          105          158           52   \n",
       "4             212           54          109          163           55   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1995          213           54          109          161           55   \n",
       "1996          208           53          109          164           56   \n",
       "1997          227           58          116          174           58   \n",
       "1998          190           48           97          145           49   \n",
       "1999          215           55          111          166           56   \n",
       "\n",
       "      feature6005  feature6006  emotion_idx  \n",
       "0             100           50           13  \n",
       "1             109           52            9  \n",
       "2              87           40            6  \n",
       "3             105           53           20  \n",
       "4             109           54            9  \n",
       "...           ...          ...          ...  \n",
       "1995          107           52            7  \n",
       "1996          111           55           20  \n",
       "1997          116           58           19  \n",
       "1998           97           48           17  \n",
       "1999          111           55           18  \n",
       "\n",
       "[2000 rows x 6007 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/59482/Desktop/Columbia/Second Term/ads/Project3/Spring2020-Project3-ads-spring2020-project3-group3/data/'\n",
    "dat_train1 = pd.read_csv(path+\"dat_train1.csv\")\n",
    "dat_train2 = pd.read_csv(path+\"dat_train2.csv\")\n",
    "dat_train=pd.concat([dat_train1,dat_train2],ignore_index=True)\n",
    "dat_test=pd.read_csv(path+\"dat_test.csv\")\n",
    "dat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3859101 ,  0.42894874, -0.15423943, ..., -0.32021489,\n",
       "         1.0694245 ,  0.41341669],\n",
       "       [-0.64381387, -1.14091168, -0.15044509, ..., -1.61463967,\n",
       "        -2.71085251, -0.48615836],\n",
       "       [-1.60667719, -1.37835656,  0.79087003, ...,  1.25159942,\n",
       "        -1.81300267,  2.12878709],\n",
       "       ...,\n",
       "       [ 1.45348759, -0.41980384, -0.72160376, ...,  0.0103879 ,\n",
       "         1.59941309, -0.2952564 ],\n",
       "       [-0.00503608, -0.32499587, -1.27477844, ...,  1.01079509,\n",
       "         0.37585835, -0.4418095 ],\n",
       "       [ 1.26017818,  0.74884621,  0.35056416, ...,  0.33231985,\n",
       "         0.98482388, -1.19987908]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=dat_train.iloc[:,:-1]\n",
    "Y_train=dat_train.iloc[:,-1]\n",
    "\n",
    "X_test=dat_test.iloc[:,:-1]\n",
    "Y_test=dat_test.iloc[:,-1]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "X_train_PCA = pca.fit_transform(X_train)\n",
    "X_train_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_PCA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.53867102,  0.29023548,  0.27804837, ...,  0.65310612,\n",
       "        -0.35707205, -0.00646688],\n",
       "       [ 0.73391199, -0.31705034,  1.1553738 , ..., -0.59843637,\n",
       "        -1.16381385,  0.38111103],\n",
       "       [ 0.58271613, -0.31543925,  1.07140477, ...,  1.49959578,\n",
       "         1.30442532,  1.26280335],\n",
       "       ...,\n",
       "       [-0.64984464,  0.56098929, -0.19341404, ...,  1.26425914,\n",
       "        -0.20173876,  0.75145747],\n",
       "       [-0.28863336, -1.1846612 , -0.10493293, ..., -1.16047134,\n",
       "        -0.27463411, -0.67990864],\n",
       "       [-0.34002069,  1.82417531,  2.74760097, ...,  0.53858538,\n",
       "        -2.13547731,  2.7507197 ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_PCA = pca.transform(X_test)\n",
    "X_test_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_PCA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform x\n",
    "X_train_CNN = X_train_PCA.reshape(2000, 90,1)\n",
    "X_test_CNN = X_test_PCA.reshape(500, 90,1)\n",
    "#normalize x\n",
    "X_train_CNN = X_train_CNN - np.mean(X_train_CNN, axis=0)\n",
    "X_train_CNN = X_train_CNN/np.std(X_train_CNN, axis=0)\n",
    "\n",
    "num_classes = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 88, 100)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 86, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 86, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 84, 100)           30100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 84, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               840100    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 22)                2222      \n",
      "=================================================================\n",
      "Total params: 902,922\n",
      "Trainable params: 902,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "#first layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu', kernel_regularizer=l2(0.1)))\n",
    "#Second layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Third layer is Convolution Layer\n",
    "model.add(Conv1D(100, (3), input_shape=(90,1), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Fourth layer is Flatten Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "#Fifth layer is Dense Layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#Sixth layer is Dense Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1101 - accuracy: 0.9675 - val_loss: 3.1570 - val_accuracy: 0.4860\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0814 - accuracy: 0.9745 - val_loss: 3.1082 - val_accuracy: 0.4740\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0712 - accuracy: 0.9815 - val_loss: 3.1811 - val_accuracy: 0.4640\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0686 - accuracy: 0.9850 - val_loss: 3.1081 - val_accuracy: 0.4760\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0620 - accuracy: 0.9875 - val_loss: 3.0733 - val_accuracy: 0.4840\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0448 - accuracy: 0.9910 - val_loss: 3.4816 - val_accuracy: 0.4900\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0570 - accuracy: 0.9870 - val_loss: 3.2421 - val_accuracy: 0.4740\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0579 - accuracy: 0.9865 - val_loss: 3.2634 - val_accuracy: 0.4840\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0468 - accuracy: 0.9890 - val_loss: 3.3544 - val_accuracy: 0.4740\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 3.4673 - val_accuracy: 0.4840\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0625 - accuracy: 0.9855 - val_loss: 3.2731 - val_accuracy: 0.4700\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0503 - accuracy: 0.9870 - val_loss: 3.3928 - val_accuracy: 0.4800\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0489 - accuracy: 0.9865 - val_loss: 3.3003 - val_accuracy: 0.4640\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0295 - accuracy: 0.9945 - val_loss: 3.5696 - val_accuracy: 0.4940\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0545 - accuracy: 0.9860 - val_loss: 3.3210 - val_accuracy: 0.4720\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0334 - accuracy: 0.9940 - val_loss: 3.5513 - val_accuracy: 0.4640\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0380 - accuracy: 0.9925 - val_loss: 3.6176 - val_accuracy: 0.4780\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0423 - accuracy: 0.9890 - val_loss: 3.6863 - val_accuracy: 0.4720\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0520 - accuracy: 0.9885 - val_loss: 3.4813 - val_accuracy: 0.4560\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 3.6033 - val_accuracy: 0.4660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e7b846f408>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_binary = keras.utils.to_categorical(Y_train-1, num_classes)\n",
    "Y_test_binary = keras.utils.to_categorical(Y_test-1, num_classes)\n",
    "model.fit(X_train_CNN, Y_train_binary,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "         validation_data=(X_test_CNN, Y_test_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
