{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk, re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load feeds into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "google_json=open(\"/Github/google_deduplicated.json\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_text = []\n",
    "\n",
    "for feed in google_json:\n",
    "    a = json.loads(feed)\n",
    "    feed_text.append(a['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text: 18116\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of text: \" + str(len(feed_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_stories(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.replace(\"'s\", \" \").replace(\"n’t\", \" not\").replace(\"’ve\", \" have\")\n",
    "        token = re.sub(r'[^a-zA-Z0-9 ]', '', token)\n",
    "        if token not in stopwords:\n",
    "            filtered_tokens.append(token.lower())\n",
    "    \n",
    "    lemmas = [lmtzr.lemmatize(t,'v') for t in filtered_tokens]\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through multiple testings, the best results for topic modeling are the below parameters\n",
    "#max_df = 0.15\n",
    "#min_df = 0.01\n",
    "#max_features = 1000\n",
    "#max_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lda_model(tf, tf_vectorizer, num_topics, max_iter, n_top_words):\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=max_iter, learning_method='batch', learning_offset=10, random_state=1)\n",
    "    lda.fit(tf)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "    topics = dict()\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        topics[topic_idx] = [tf_feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]\n",
    "\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.15, min_df=0.01, max_features=1000, tokenizer=tokenize_stories, ngram_range=(1, 1))\n",
    "tf = tf_vectorizer.fit_transform(feed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, max_iter=500, learning_method='batch', learning_offset=10, random_state=1)\n",
    "lda_model = lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['cloud', 'technology', 'team', 'digital', 'health', 'network', 'platform', 'design', 'tool', 'develop'], 1: ['page', 'https', 'website', 'web', 'site', 'chrome', 'browser', 'link', 'file', 'user'], 2: ['trump', 'podcast', 'president', 'tech', 'law', 'privacy', 'government', 'order', 'tweet', 'claim'], 3: ['police', 'black', 'coronavirus', 'city', 'health', 'case', 'officer', 'floyd', 'protest', 'pm'], 4: ['million', 'india', 'per', 'pay', 'digital', 'increase', 'billion', 'stock', 'businesses', 'revenue'], 5: ['game', 'good', 'really', 'lot', 'school', 'nt', 'things', 'students', 'something', 'every'], 6: ['android', 'phone', 'apps', 'apple', 'de', 'game', 'device', 'pixel', 'store', 'devices'], 7: ['log', 'smart', 'tv', 'amazon', 'music', 'voice', 'stream', 'assistant', 'youtube', 'never']}\n"
     ]
    }
   ],
   "source": [
    "topics = test_lda_model(tf, tf_vectorizer, 8, 500, 10)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA on 10 random articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sample = random.sample(range(1, len(feed_text)), 10)\n",
    "\n",
    "random_10_text = [feed_text[i] for i in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results = lda.fit_transform(tf)\n",
    "sample_text_results = lda_results[sample,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.949724</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.407885</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.057595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.225241</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.610612</td>\n",
       "      <td>0.139092</td>\n",
       "      <td>0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15396</th>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.136717</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.201019</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>0.001508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>0.208270</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.196529</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.254618</td>\n",
       "      <td>0.058234</td>\n",
       "      <td>0.280810</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10721</th>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.200276</td>\n",
       "      <td>0.588801</td>\n",
       "      <td>0.145510</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>0.256704</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.492184</td>\n",
       "      <td>0.188476</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.026496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.902770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13220</th>\n",
       "      <td>0.621430</td>\n",
       "      <td>0.345943</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.458526</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>0.066695</td>\n",
       "      <td>0.389936</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "3387   0.001625  0.001625  0.001626  0.001626  0.040522  0.001626  0.949724   \n",
       "7547   0.002720  0.002722  0.002723  0.520908  0.002720  0.407885  0.002725   \n",
       "16954  0.005012  0.005002  0.005006  0.225241  0.005014  0.610612  0.139092   \n",
       "15396  0.381700  0.136717  0.001509  0.001507  0.001507  0.201019  0.274533   \n",
       "4546   0.208270  0.000513  0.196529  0.000513  0.254618  0.058234  0.280810   \n",
       "10721  0.001150  0.001148  0.200276  0.588801  0.145510  0.060818  0.001148   \n",
       "6700   0.256704  0.000921  0.033379  0.000921  0.492184  0.188476  0.000920   \n",
       "12455  0.013889  0.013892  0.013891  0.013889  0.013889  0.013891  0.013889   \n",
       "13220  0.621430  0.345943  0.005442  0.005436  0.005438  0.005437  0.005438   \n",
       "15689  0.008415  0.000057  0.458526  0.076257  0.066695  0.389936  0.000057   \n",
       "\n",
       "              7  \n",
       "3387   0.001626  \n",
       "7547   0.057595  \n",
       "16954  0.005020  \n",
       "15396  0.001508  \n",
       "4546   0.000513  \n",
       "10721  0.001148  \n",
       "6700   0.026496  \n",
       "12455  0.902770  \n",
       "13220  0.005436  \n",
       "15689  0.000057  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(sample_text_results, index=sample)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For index 3387, the max value comes from topics 6, with a max value of 0.9497\n",
      "For index 7547, the max value comes from topics 3, with a max value of 0.5209\n",
      "For index 16954, the max value comes from topics 5, with a max value of 0.6106\n",
      "For index 15396, the max value comes from topics 0, with a max value of 0.3817\n",
      "For index 4546, the max value comes from topics 6, with a max value of 0.2808\n",
      "For index 10721, the max value comes from topics 3, with a max value of 0.5888\n",
      "For index 6700, the max value comes from topics 4, with a max value of 0.4922\n",
      "For index 12455, the max value comes from topics 7, with a max value of 0.9028\n",
      "For index 13220, the max value comes from topics 0, with a max value of 0.6214\n",
      "For index 15689, the max value comes from topics 2, with a max value of 0.4585\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(sample)):\n",
    "    print(\"For index \" + str(sample[x])+\n",
    "         \", the max value comes from topics \" + str(int(df.iloc[[x]].idxmax(1)))+\n",
    "         \", with a max value of \" + str(round(float(max(sample_text_results[x])),4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
